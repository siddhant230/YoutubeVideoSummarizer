{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "transcription extraction ✅ <br>\n",
        "summarization ✅"
      ],
      "metadata": {
        "id": "9SBmMfadOOYp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fhrAaJK4BZVH"
      },
      "outputs": [],
      "source": [
        "!pip install -q youtube_transcript_api\n",
        "!pip install -q bert-extractive-summarizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import spacy\n",
        "import requests\n",
        "from string import punctuation\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "from summarizer import Summarizer\n",
        "from youtube_transcript_api import YouTubeTranscriptApi as yta"
      ],
      "metadata": {
        "id": "tPYKafWoBfVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d34b3368-e5f7-4fa9-8765-2d4e5b91e0c2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_model = Summarizer()\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMYFKEE3ZXEq",
        "outputId": "246c3f66-fc6f-4acf-a88d-a147f62397a3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ids(video_links):\n",
        "  ids = []\n",
        "  for links in video_links:\n",
        "    id = links.split(\"v=\")[-1]\n",
        "    ids.append(id)\n",
        "  return ids"
      ],
      "metadata": {
        "id": "LpRA0rdpZg6x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text(text_content):\n",
        "  transcript = \"\"\n",
        "  for value_dict in text_content:\n",
        "    transcript += \" \" + value_dict['text'] if (value_dict['text'][0] != \"[\" and value_dict['text'][-1] != \"]\") else \" \"\n",
        "  return transcript\n",
        "\n",
        "def get_transcript_from_ids(video_ids):\n",
        "  transcripts = {}\n",
        "  data = yta.get_transcripts(video_ids)[0]\n",
        "  for video_id in data:\n",
        "    print(f\"Getting transcript for {video_id}\")\n",
        "    transcript = extract_text(data[video_id])\n",
        "    transcripts[video_id]= transcript.strip().rstrip()\n",
        "    if transcript == \"\":\n",
        "      print(f\"No transcript found for {video_id}\")\n",
        "    else:\n",
        "      print(f\"Successfully extracted transcript for {video_id}\")\n",
        "    print(\"------------------------\")\n",
        "  return transcripts"
      ],
      "metadata": {
        "id": "Sl4I6lCWEm1E"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "  doc = nlp(text)\n",
        "  joined_text = \".\".join([sent.text.capitalize() for sent in doc.sents if len(sent.text.split(\" \"))>3])\n",
        "  return joined_text"
      ],
      "metadata": {
        "id": "gBPnn7YVVIUF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_info(ids):\n",
        "    # getting the request from url\n",
        "    metadata = {}\n",
        "    for id in ids:\n",
        "      url = f\"https://www.youtube.com/watch?v={id}\"\n",
        "      r = requests.get(url)\n",
        "      # converting the text\n",
        "      base_text = r.text.split(\"twoColumnWatchNextResults\")[1].split(\"videoPrimaryInfoRenderer:\")[0]\n",
        "      title = base_text.split('\"title\":')[1].split(\"}]}\")[0].split('\"runs\":[{\"text\":')[1].replace('\"',\"\")\n",
        "      views = base_text.split('\"title\":')[1].split(\"videoViewCountRenderer\")[1].split(\"}\")[0].split('\"simpleText\":')[1].split(\" \")[0].replace('\"',\"\")\n",
        "      likes = base_text.split(\"segmentedLikeDislikeButtonRenderer\")[1].split(\"defaultText\")[1].split(\"}}\")[0].split('\"label\":')[1].split(\" \")[0].replace('\"',\"\")\n",
        "      meta = {\"title\":title, \"likes\":likes, \"views\":views}\n",
        "      print(f\"{id}: {meta}\")\n",
        "      metadata[id] = meta\n",
        "    return metadata"
      ],
      "metadata": {
        "id": "sTDiK-WRlnrU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(video_links, save_path=\"/content/summaries\", ratio=0.6):\n",
        "  video_ids = get_ids(video_links)\n",
        "  metadata = scrape_info(video_ids)\n",
        "  print(f\"Extracted ids and its meta info: {video_ids}\")\n",
        "  transcripts_data = get_transcript_from_ids(video_ids)\n",
        "  \n",
        "  for id in transcripts_data:\n",
        "    print(f\"---------------video ID : {id} | title : {metadata[id]['title']} -----------------\")\n",
        "    print(f\"Preprcoessing transcript\")\n",
        "    clean_text = preprocess_text(transcripts_data[id])\n",
        "    print(\"Preprocessing complete\")\n",
        "    print(\"Summarizing...\")\n",
        "    result = summary_model(clean_text, ratio=ratio)\n",
        "    print(\"Summarization complete\")\n",
        "    print(\"saving data...\")\n",
        "    json_result = {}\n",
        "    for idx, r in enumerate(result.split(\".\")):\n",
        "      r = r.strip().rstrip()\n",
        "      if r != '':\n",
        "        json_result[idx] = r\n",
        "\n",
        "    save_file = {\"url\": f\"https://www.youtube.com/watch?v={id}\", \"video id\":id, \"metadata\":metadata[id], \"points\":json_result, \"full_summary\":result, \"transcript\":transcripts_data[id]}\n",
        "    with open(f\"{save_path}/{metadata[id]['title'].replace(' ', '_')}.json\", \"w\") as f:\n",
        "      json.dump(save_file, f, indent=4)\n",
        "    print(\"saved!!\")"
      ],
      "metadata": {
        "id": "FBXbIORuKgDV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  video_links = [\"https://www.youtube.com/watch?v=OdzAQFmyxNo\",\n",
        "                 \"https://www.youtube.com/watch?v=mU7hdGKOGyk\"]\n",
        "  main(video_links)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeK5LscTZ81k",
        "outputId": "c4e2cb06-3bd5-4a63-e3ec-00fa81ccd745"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OdzAQFmyxNo: {'title': 'Freud and Philosophy', 'likes': '4,108', 'views': '151,865'}\n",
            "mU7hdGKOGyk: {'title': 'Machiavelli', 'likes': '3,050', 'views': '81,902'}\n",
            "Extracted ids and its meta info: ['OdzAQFmyxNo', 'mU7hdGKOGyk']\n",
            "Getting transcript for OdzAQFmyxNo\n",
            "Successfully extracted transcript for OdzAQFmyxNo\n",
            "------------------------\n",
            "Getting transcript for mU7hdGKOGyk\n",
            "Successfully extracted transcript for mU7hdGKOGyk\n",
            "------------------------\n",
            "---------------video ID : OdzAQFmyxNo | title : Freud and Philosophy -----------------\n",
            "Preprcoessing transcript\n",
            "Preprocessing complete\n",
            "Summarizing...\n",
            "Summarization complete\n",
            "saving data...\n",
            "saved!!\n",
            "---------------video ID : mU7hdGKOGyk | title : Machiavelli -----------------\n",
            "Preprcoessing transcript\n",
            "Preprocessing complete\n",
            "Summarizing...\n",
            "Summarization complete\n",
            "saving data...\n",
            "saved!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qTnmhe4Jodvn"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}